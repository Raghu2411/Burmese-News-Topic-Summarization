{"cells":[{"cell_type":"markdown","id":"14410483","metadata":{"id":"14410483"},"source":["# Hugging Face - Summarization in Japanese\n","\n","This source code builds the fine-tuned model of [google/mt5-small](https://huggingface.co/google/mt5-small) for Japanese summarization.\n","\n","For more background and details, see [this blog post](https://tsmatz.wordpress.com/2022/11/25/huggingface-japanese-summarization/).\n","\n","*back to [index](https://github.com/tsmatz/huggingface-finetune-japanese/)*"]},{"cell_type":"markdown","id":"8ec4dd94","metadata":{"id":"8ec4dd94"},"source":["## Install required packages\n","\n","In order to install core components, see [Readme](https://github.com/tsmatz/huggingface-finetune-japanese/).<br>\n","Install additional packages for running this notebook as follows."]},{"cell_type":"markdown","id":"ab3bf825","metadata":{"id":"ab3bf825"},"source":["Install packages depending on T5 tokenizer."]},{"cell_type":"code","source":["!pip install evaluate\n","!pip install transformers\n","!pip install datasets\n","!pip install transformers[torch]\n","!pip install accelerate -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDETrfuKW8PA","outputId":"d2911798-4ba8-4888-a4f9-bb63fb26676f"},"id":"yDETrfuKW8PA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.17.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":null,"id":"12a86426","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12a86426","outputId":"4304e575-f938-450a-d42f-9d47ecc62848"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n"]}],"source":["!pip install protobuf==3.20.3"]},{"cell_type":"markdown","id":"d4b66d94","metadata":{"id":"d4b66d94"},"source":["Install packages depending on rouge evaluation."]},{"cell_type":"code","execution_count":null,"id":"aee740d4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aee740d4","outputId":"239a3515-47d5-48fc-8c70-0091744414ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (1.4.0)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"]}],"source":["!pip install absl-py rouge_score nltk"]},{"cell_type":"markdown","id":"631a81ff","metadata":{"id":"631a81ff"},"source":["Install other dependent packages."]},{"cell_type":"code","execution_count":null,"id":"95588a34","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95588a34","outputId":"e0f94a4f-b4c7-4c9a-aab9-27be92f78580"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"]}],"source":["!pip install numpy"]},{"cell_type":"markdown","id":"c04ef40e","metadata":{"id":"c04ef40e"},"source":["## Check device\n","\n","Check whether GPU is available."]},{"cell_type":"code","execution_count":null,"id":"f5bc098b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f5bc098b","outputId":"f9e41549-8a52-4685-9f14-5d1b14d28351"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is enabled.\n","device count: 1, current device: 0\n"]}],"source":["import torch\n","\n","if torch.cuda.is_available():\n","    print(\"GPU is enabled.\")\n","    print(\"device count: {}, current device: {}\".format(torch.cuda.device_count(), torch.cuda.current_device()))\n","else:\n","    print(\"GPU is not enabled.\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","id":"5163ab77","metadata":{"id":"5163ab77"},"source":["## Prepare data\n","\n","In this example, we use [XL-Sum Japanese dataset](https://huggingface.co/datasets/csebuetnlp/xlsum/viewer/japanese) in Hugging Face, which is the annotated article-summary pairs generated by BBC.<br>\n","This dataset has around 7000 samples for training."]},{"cell_type":"code","execution_count":null,"id":"20a1866b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20a1866b","outputId":"83f234fb-58e6-465f-b737-ab2d8b301833"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'url', 'title', 'summary', 'text'],\n","        num_rows: 4569\n","    })\n","    test: Dataset({\n","        features: ['id', 'url', 'title', 'summary', 'text'],\n","        num_rows: 570\n","    })\n","    validation: Dataset({\n","        features: ['id', 'url', 'title', 'summary', 'text'],\n","        num_rows: 570\n","    })\n","})"]},"metadata":{},"execution_count":6}],"source":["from datasets import load_dataset\n","\n","ds = load_dataset(\"csebuetnlp/xlsum\", name=\"burmese\")\n","ds"]},{"cell_type":"code","execution_count":null,"id":"c8da181d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8da181d","outputId":"2e275dfd-35ab-4853-b756-867ee63b8a56"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '151203_syria_uk_airstrikes',\n"," 'url': 'https://www.bbc.com/burmese/world/2015/12/151203_syria_uk_airstrikes',\n"," 'title': 'ဆီးရီးယား IS တွေကို ယူကေ လေကြောင်းတိုက်ခိုက်',\n"," 'summary': 'ဗြိတိသျှ တော်ဝင် လေတပ်ရဲ့ တိုနေဒိုး တိုက်လေယာဉ်တွေက ဆီးရီးယားမှာ ရှိတဲ့ IS အစ္စလာမ္မစ် နိုင်ငံအဖွဲ့ အပေါ် လေကြောင်း တိုက်ခိုက်မှုတွေ လုပ်ခဲ့တယ်လို့ ယူကေ ကာကွယ်ရေး ဝန်ကြီးဌာနက အတည်ပြု ပြောဆိုခဲ့ပါတယ်။',\n"," 'text': 'IS ပိုင် ရေနံတွင်းတွေကို ဗြိတိသျှ တိုက်လေယာဉ် ၄ စီးက တိုက်ခိုက်ခဲ့ ဗုံးကြဲ တိုက်ခိုက်ဖို့ အတွက် ယူကေ အမတ်တွေ အတည်ပြုပြီး မကြာမီမှာပဲ ဆိုက်ပရပ်စ်မှာ ရှိတဲ့ Akrotiri အက်ရော့တီရီ လေတပ်စခန်းက တိုနေးဒိုး တိုက်လေယာဉ် ၄ စီး တိုက်ခိုက်မှုမှာ ပါဝင် ခဲ့ပါတယ်။ ဆီးရီးယား အရှေ့ပိုင်းက IS တွေ ထိန်းချုပ်ထားတဲ့ ရေနံတွင်းတွေကို တိုက်ခိုက် ထိမှန်ခဲ့တယ်လို့ ကာကွယ်ရေး ဝန်ကြီးက ပြောပါတယ်။ ဝန်ကြီးချုပ် ဒေးဗစ် ကင်မရွန်း ကတော့ IS အပေါ် တိုက်ခိုက်မှုတွေဟာ အချိန် ကြာမြင့်မှာ ဖြစ်ပြီး ပုံမှန် ပြုလုပ်သွားဖို့ လိုတယ်လို့ သတိပေး ပြောဆို ခဲ့ပါတယ်။ IS အပေါ် လေကြောင်း တိုက်ဖို့အတွက် ယူကေ ပါလီမန်မှာ ဗုဒ္ဓဟူးနေ့က ဆွေးနွေးငြင်းခုံပြီး မဲခွဲ ဆုံးဖြတ်ရာမှာ ထောက်ခံမဲ ၃၉၇ မဲ၊ ကန့်ကွက်မဲ ၂၂၃ မဲနဲ့ အတည်ပြုခဲ့တာ ဖြစ်ပါတယ်။ အက်ရော့တီရီ လေတပ်စခန်းမှာ ရှိနှင့်ပြီးဖြစ်တဲ့ တိုက်လေယာဉ် ၈ စီး အပြင် နောက်ထပ် ၈ စီး ထပ်ပို့လိုက်တယ် လို့လည်း ယူကေ ကာကွယ်ရေး ဝန်ကြီး မိုက်ကယ် ဖာလန်က ပြောပါတယ်။'}"]},"metadata":{},"execution_count":7}],"source":["ds[\"train\"][0]"]},{"cell_type":"markdown","id":"453c922d","metadata":{"id":"453c922d"},"source":["To generate inputs for fine-tuning, now I tokenize each text and convert into token ids.\n","\n","First, load tokenizer in pre-trained ```google/mt5-small``` model."]},{"cell_type":"code","execution_count":null,"id":"c42045d0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c42045d0","outputId":"b5f52112-fff1-4c32-fcf4-d3204454d983"},"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoTokenizer\n","\n","t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"]},{"cell_type":"markdown","id":"bd8231f7","metadata":{"id":"bd8231f7"},"source":["For fine-tuning, apply tokenization for dataset."]},{"cell_type":"code","execution_count":null,"id":"714d1453","metadata":{"id":"714d1453"},"outputs":[],"source":["def tokenize_sample_data(data):\n","    # Max token size is 14536 and 215 for inputs and labels, respectively.\n","    # Here I restrict these token size.\n","    input_feature = t5_tokenizer(data[\"text\"], truncation=True, max_length=1024)\n","    label = t5_tokenizer(data[\"summary\"], truncation=True, max_length=128)\n","    return {\n","        \"input_ids\": input_feature[\"input_ids\"],\n","        \"attention_mask\": input_feature[\"attention_mask\"],\n","        \"labels\": label[\"input_ids\"],\n","    }"]},{"cell_type":"code","execution_count":null,"id":"26b32615","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":292,"referenced_widgets":["b98efe7c02c94dd59c489c55c425efb3","cfc83781cb48416db03d9d6a0ebecc06","5abfdbab30db4406aadc4f42dd0d388d","0eaefc4c984a4b9eb0ce41467f297148","6b48d53872f2490f80e5dc170706fa99","40b3a0ae71c347bf94cc33bab668d351","c2e37d7d4e8b4d01baca58cfddd26828","0ef29c7796f640b4833b653b94a5fa28","caa141f9a49c44428675b2c1fd08b4ee","6b25d6811c6a4d5b99b808ec074c128d","bd37436537bc4e279ffcc2f6d4945298"]},"id":"26b32615","outputId":"215ea4de-77b5-4c50-c0d6-28454376e3b9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/570 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b98efe7c02c94dd59c489c55c425efb3"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 4569\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 570\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 570\n","    })\n","})"]},"metadata":{},"execution_count":10}],"source":["tokenized_ds = ds.map(\n","    tokenize_sample_data,\n","    remove_columns=[\"id\", \"url\", \"title\", \"summary\", \"text\"],\n","    batched=True,\n","    batch_size=128)\n","tokenized_ds"]},{"cell_type":"markdown","id":"692dd056","metadata":{"id":"692dd056"},"source":["## Fine-tune"]},{"cell_type":"markdown","id":"4bf379a1","metadata":{"id":"4bf379a1"},"source":["In this example, we use mT5 model.<br>\n","There exist several sizes of mT5 and I'll use small one (```google/mt5-small```) to fit to memory in my machine. The name is \"small\", but it's still so large."]},{"cell_type":"code","execution_count":null,"id":"39cab1c7","metadata":{"id":"39cab1c7"},"outputs":[],"source":["from transformers import AutoConfig, AutoModelForSeq2SeqLM\n","\n","# see https://huggingface.co/docs/transformers/main_classes/configuration\n","mt5_config = AutoConfig.from_pretrained(\n","    \"google/mt5-small\",\n","    max_length=128,\n","    length_penalty=0.6,\n","    no_repeat_ngram_size=2,\n","    num_beams=15,\n",")\n","model = (AutoModelForSeq2SeqLM\n","         .from_pretrained(\"google/mt5-small\", config=mt5_config)\n","         .to(device))"]},{"cell_type":"markdown","id":"30cb5336","metadata":{"id":"30cb5336"},"source":["We prepare data collator, which works for preprocessing data.\n","\n","For the sequence-to-sequence (seq2seq) task, we need to not only stack the inputs for encoder, but also prepare for the decoder side. In seq2seq setup, a common technique called \"teach forcing\" will then be applied in decoder.<br>\n","These tasks are not needed to manually setup in Hugging Face, and ```DataCollatorForSeq2Seq``` will take care of all steps.\n","\n","In this collator, the padded token will also be filled with label id -100.<br>\n","This token will then be ignored in the sebsequent loss computation and evaluation."]},{"cell_type":"code","execution_count":null,"id":"bc213f22","metadata":{"id":"bc213f22"},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(\n","    t5_tokenizer,\n","    model=model,\n","    return_tensors=\"pt\")"]},{"cell_type":"markdown","id":"6b9c9f14","metadata":{"id":"6b9c9f14"},"source":["We also prepare metrics function for evaluation in the training.<br>\n","Measuring the quality of generated text is very difficult, and BLEU and ROUGE are often used.\n","\n","Briefly speaking, BLEU measures how many of n-grams in the generated (predicted) text are overlaped in the reference text. This score is used for evaluation, especially in the machine translation task.\n","However, in summarization, we need all important words (which appears on the reference text) in the generated text. This is because we often use ROUGE in summarization tasks.\n","The idea of ROUGE is similar to BLEU, but it also measures how many of n-grams in the reference text appears in the generated (predicted) text. (This is why the name of ROUGE includes \"RO\", which means \"Recall-Oriented\".)<br>\n","There also exist variations, ROUGE-L and ROUGE-Lsum, which also measures the longest common substrings (LCS).\n","\n","In Hugging Face, you don't need to manually implement these logics and can use built-in objects for scoring these matrics.<br>\n","In this example, I have configured mT5 tokenization as custom tokenization in computation (which is based on SentencePiece Unigram segmentation), because the white space tokenization is used as default in ROUGE evaluation.\n","\n","> Note : You can also specify multilingual stemmer.\n","\n","> Note : As I have mentioned above, the padded token id becomes -100 by data collator and I then also convert it into padded token id before processing."]},{"cell_type":"code","execution_count":null,"id":"f5dd0da9","metadata":{"id":"f5dd0da9"},"outputs":[],"source":["import evaluate\n","import numpy as np\n","from nltk.tokenize import RegexpTokenizer\n","\n","rouge_metric = evaluate.load(\"rouge\")\n","\n","def tokenize_sentence(arg):\n","    encoded_arg = t5_tokenizer(arg)\n","    return t5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n","\n","def metrics_func(eval_arg):\n","    preds, labels = eval_arg\n","    # Replace -100\n","    labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n","    # Convert id tokens to text\n","    text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    # Insert a line break (\\n) in each sentence for ROUGE scoring\n","    # (Note : Please change this code, when you perform on other languages except for Japanese)\n","    text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\", \"။\" , \"၊\" )) else p + \"。\") for p in text_preds]\n","    text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n","    #sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n","    sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。။၊]*[!！?？。။၊]')\n","\n","    text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n","    text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n","    # compute ROUGE score with custom tokenization\n","    return rouge_metric.compute(\n","        predictions=text_preds,\n","        references=text_labels,\n","        tokenizer=tokenize_sentence\n","    )"]},{"cell_type":"markdown","id":"7dde59f4","metadata":{"id":"7dde59f4"},"source":["Before fine-tuning, now I check ROUGE score with plain mT5 model. Here I check scores for top 5 rows in test dataset.\n","\n","The score is very low, because this model is not trained for any downstream tasks. (It's just trained by unsupervised approach.)\n","\n","> Note : In order to avoid suboptimal text generation, here I have applied beam search for the text generation algorithm."]},{"cell_type":"code","execution_count":null,"id":"a5e99037","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5e99037","outputId":"b33297e5-6a68-4fa6-fe9c-031f01422bab"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["{'rouge1': 0.21596275649523547,\n"," 'rouge2': 0.1224458187250594,\n"," 'rougeL': 0.2147220617061536,\n"," 'rougeLsum': 0.2082704488029278}"]},"metadata":{},"execution_count":14}],"source":["from torch.utils.data import DataLoader\n","\n","sample_dataloader = DataLoader(\n","    tokenized_ds[\"test\"].with_format(\"torch\"),\n","    collate_fn=data_collator,\n","    batch_size=5)\n","for batch in sample_dataloader:\n","    with torch.no_grad():\n","        preds = model.generate(\n","            batch[\"input_ids\"].to(device),\n","            num_beams=15,\n","            num_return_sequences=1,\n","            no_repeat_ngram_size=1,\n","            remove_invalid_values=True,\n","            max_length=128,\n","        )\n","    labels = batch[\"labels\"]\n","    break\n","\n","metrics_func([preds, labels])\n","\n","# {'rouge1': 0.21596275649523547,\n","#  'rouge2': 0.1224458187250594,\n","#  'rougeL': 0.2147220617061536,\n","#  'rougeLsum': 0.2082704488029278}"]},{"cell_type":"markdown","id":"9f4bfded","metadata":{"id":"9f4bfded"},"source":["We prepare training arguments for fine-tuning.<br>\n","In this example, we use HuggingFace transformer trainer class, with which you can run training without manually writing training loop.\n","\n","In usual training evaluation, training loss and accuracy will be computed and evaluated, by comparing the generated logits with labels. However, as we saw above, we want to evaluate ROUGE score using the predicted tokens.<br>\n","To simplify these sequence-to-sequence specific steps, here I use built-in ```Seq2SeqTrainingArguments``` and ```Seq2SeqTrainer``` classes in HuggingFace, instead of usual ```TrainingArguments``` and ```Trainer```.<br>\n","By setting ```predict_with_generate=True``` in this class, the predicted tokens generated by  ```model.generate()``` will be used in each evaluation.\n","\n","The checkpoint files (in each 500 steps) are saved in the folder named ```mt5-summarize-ja```.\n","\n","> Note : Do not use FP16 precision in mT5 fine-tuning.\n","\n","> Note : In general, the saved checkpoints in the training will become so large.<br>\n","> Set ```save_total_limit``` property (which limits the total amount of checkpoints by deleting the older ones) to save disk spaces, or expand disks in Azure VM. (See [here](https://learn.microsoft.com/en-us/azure/virtual-machines/linux/expand-disks) to expand disks in Azure.)"]},{"cell_type":"code","execution_count":null,"id":"78f28731","metadata":{"id":"78f28731"},"outputs":[],"source":["from transformers import Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir = \"mt5-summarize-ja\",\n","    log_level = \"error\",\n","    num_train_epochs = 10,\n","    learning_rate = 5e-4,\n","    lr_scheduler_type = \"linear\",\n","    warmup_steps = 90,\n","    optim = \"adafactor\",\n","    weight_decay = 0.01,\n","    per_device_train_batch_size = 2,\n","    per_device_eval_batch_size = 1,\n","    gradient_accumulation_steps = 16,\n","    evaluation_strategy = \"steps\",\n","    eval_steps = 100,\n","    predict_with_generate=True,\n","    generation_max_length = 128,\n","    save_steps = 500,\n","    logging_steps = 10,\n","    push_to_hub = False\n",")"]},{"cell_type":"markdown","id":"3978f071","metadata":{"id":"3978f071"},"source":["Build trainer. (Put it all together.)\n","\n","Because the cost of evaluation computation (ROUGE scoring) is so high, I have then decreased the number of rows in validation set."]},{"cell_type":"code","execution_count":null,"id":"bca8a572","metadata":{"id":"bca8a572"},"outputs":[],"source":["from transformers import Seq2SeqTrainer\n","trainer = Seq2SeqTrainer(\n","    model = model,\n","    args = training_args,\n","    data_collator = data_collator,\n","    compute_metrics = metrics_func,\n","    train_dataset = tokenized_ds[\"train\"],\n","    eval_dataset = tokenized_ds[\"validation\"].select(range(20)),\n","    tokenizer = t5_tokenizer,\n",")"]},{"cell_type":"markdown","id":"ce8b530f","metadata":{"id":"ce8b530f"},"source":["Now let's run training.<br>\n","As you will find, ROUGE scores are growing during training.\n","\n","> Note : As I have mentioned above, make sure that you have enough disk space."]},{"cell_type":"code","execution_count":null,"id":"a66059ec","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549},"id":"a66059ec","outputId":"0041f2c4-1304-415c-8c90-7c9d0a48bcb2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1420' max='1420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1420/1420 1:28:50, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>3.324100</td>\n","      <td>2.479476</td>\n","      <td>0.311584</td>\n","      <td>0.152303</td>\n","      <td>0.262827</td>\n","      <td>0.263187</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>2.758300</td>\n","      <td>2.270957</td>\n","      <td>0.322364</td>\n","      <td>0.145290</td>\n","      <td>0.272528</td>\n","      <td>0.272215</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.546900</td>\n","      <td>2.293579</td>\n","      <td>0.359305</td>\n","      <td>0.177212</td>\n","      <td>0.297784</td>\n","      <td>0.296315</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>2.533500</td>\n","      <td>2.191272</td>\n","      <td>0.335907</td>\n","      <td>0.152730</td>\n","      <td>0.283324</td>\n","      <td>0.284030</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>2.438300</td>\n","      <td>2.150708</td>\n","      <td>0.378321</td>\n","      <td>0.193331</td>\n","      <td>0.325641</td>\n","      <td>0.324883</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>2.367100</td>\n","      <td>2.133783</td>\n","      <td>0.355929</td>\n","      <td>0.175622</td>\n","      <td>0.298318</td>\n","      <td>0.298553</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>2.349000</td>\n","      <td>2.108918</td>\n","      <td>0.378390</td>\n","      <td>0.183986</td>\n","      <td>0.313601</td>\n","      <td>0.312135</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>2.264000</td>\n","      <td>2.135322</td>\n","      <td>0.388724</td>\n","      <td>0.204001</td>\n","      <td>0.323286</td>\n","      <td>0.322802</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>2.157700</td>\n","      <td>2.110123</td>\n","      <td>0.386881</td>\n","      <td>0.197202</td>\n","      <td>0.326367</td>\n","      <td>0.326241</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.131500</td>\n","      <td>2.090510</td>\n","      <td>0.400456</td>\n","      <td>0.209173</td>\n","      <td>0.335530</td>\n","      <td>0.333564</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>2.141800</td>\n","      <td>2.089314</td>\n","      <td>0.360273</td>\n","      <td>0.187141</td>\n","      <td>0.304837</td>\n","      <td>0.304867</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>2.074400</td>\n","      <td>2.088130</td>\n","      <td>0.391389</td>\n","      <td>0.208791</td>\n","      <td>0.327757</td>\n","      <td>0.328035</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>2.094400</td>\n","      <td>2.070921</td>\n","      <td>0.383359</td>\n","      <td>0.196049</td>\n","      <td>0.317870</td>\n","      <td>0.318378</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>2.101500</td>\n","      <td>2.069465</td>\n","      <td>0.382098</td>\n","      <td>0.194670</td>\n","      <td>0.315390</td>\n","      <td>0.316339</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1420, training_loss=2.672717551110496, metrics={'train_runtime': 5334.6332, 'train_samples_per_second': 8.565, 'train_steps_per_second': 0.266, 'total_flos': 3.435385056043008e+16, 'train_loss': 2.672717551110496, 'epoch': 9.94})"]},"metadata":{},"execution_count":17}],"source":["trainer.train()\n","# TrainOutput(global_step=1420, training_loss=2.672717551110496, metrics={'train_runtime': 5334.6332, 'train_samples_per_second': 8.565, 'train_steps_per_second': 0.266,\n","#  'total_flos': 3.435385056043008e+16, 'train_loss': 2.672717551110496, 'epoch': 9.94})"]},{"cell_type":"markdown","id":"44578fb6","metadata":{"id":"44578fb6"},"source":["In order to use it later, you can save the trained model."]},{"cell_type":"code","execution_count":null,"id":"0710012a","metadata":{"id":"0710012a"},"outputs":[],"source":["import os\n","\n","os.makedirs(\"./trained_for_summarization_jp\", exist_ok=True)\n","if hasattr(trainer.model, \"module\"):\n","    trainer.model.module.save_pretrained(\"./trained_for_summarization_jp\")\n","else:\n","    trainer.model.save_pretrained(\"./trained_for_summarization_jp\")"]},{"cell_type":"markdown","id":"bf2efe66","metadata":{"id":"bf2efe66"},"source":["Load pre-trained model from local."]},{"cell_type":"code","execution_count":null,"id":"2be7c430","metadata":{"id":"2be7c430"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","model = (AutoModelForSeq2SeqLM\n","         .from_pretrained(\"./trained_for_summarization_jp\")\n","         .to(device))"]},{"cell_type":"markdown","id":"5ca6f566","metadata":{"id":"5ca6f566"},"source":["## Generate Text (Summarize) with Fine-Tuned Model\n","\n","Now let's see how it generates text for summarization with fine-tuned model.<br>\n","Here I generate the summarized text of test data, which has not seen in the training set.\n","\n","> Note : The article in XL-Sum dataset is created by removing the first sentence (headline sentence) of BBC news source, and the first sentence is then used for summary.<br>\n",">  For this reason, there might exist several mismatch between article and summary in test data. (Choose appropriate samples for checking.)"]},{"cell_type":"code","execution_count":null,"id":"4ca11263","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ca11263","outputId":"04423ec5-4050-4ee7-87ad-13dc65945c20"},"outputs":[{"output_type":"stream","name":"stdout","text":["***** Input's Text *****\n","မဆောက်ဖြစ်တော့တဲ့ အိုလံပစ်ကွင်း အဲဒီ အားကစား ကွင်းကြီး တည်ဆောက်ဖို့အတွက် ကုန်ကျ စားရိတ် များလွန်းတာကြောင့် ဝေဖန်ခံနေရတာ ဖြစ်ပါတယ်။ အားကစားကွင်း အတွက် တည်ဆောက်စားရိတ် ဒေါ်လာ ၂ ဘီလျံလောက် ကုန်ကျလိမ့်မယ်လို့ ခန့်မှန်းထားတာပါ။ ဂျပန်ဝန်ကြီးချုပ် ရှင်ဇိုအာဘေးက ဒါနဲ့ပတ်သက်လို့ အသေအချာ ပြန်လည် သုံးသပ်ရမယ်လို့ ဆိုပါတယ်။ မစ္စတာအာဘေးက ဆောက်လုပ်စားရိတ်က သိပ်များနေလို့ ပြည်သူကရော၊ အားကစားလောက ကရော ဝေဖန်နေကြတဲ့ အကြောင်း ဒီပုံစံနဲ့ ဆိုရင် အားလုံး ပါဝင်ဆင်နွှဲကြတဲ့ ပြိုင်ပွဲကြီး တခုကျင်းပ သွားဖို့ဆိုတာ မဖြစ်နိုင်ဘူးလို့ သူယူဆတဲ့အကြောင်း ပြောသွားခဲ့ပါတယ်။ ဒီအားကစားကွင်းကို ပိသုကာ ဇာဟာ ဟာဒစ်က ဒီဇိုင်းဆွဲ ပုံစံ ထုတ်ခဲ့တာ ဖြစ်ပြီး သူက ဒီလောက် ကုန်ကျစားရိတ် များတာဟာ သူ့ဒီဇိုင်းကြောင့် ဖြစ်တယ်လို့ ပြောနေကြတာနဲ့ ပတ်သက်လို့ ငြင်းဆို လိုက်ပါတယ်။ ဇာဟာ ဟာဒစ်က ဒေသတွင်းမှာ တည်ဆောက်ရေး စားရိတ်တွေ တက်လာတာနဲ့ စီမံကိန်းပြီးစီးဖို့ ရက်အတိအကျ သတ်မှတ်ထားတာ တွေကြောင့် ဒီလိုဖြစ်ခဲ့တာလို့ ဆိုပါတယ်။ အဲ့ဒီအားကစားကွင်းကို လာမယ့် ၂၀၁၉ ရဂ်ဘီကမ္ဘာ့ဖလား ကျင်းပရင် ဖွင့်လှစ်ဖို့ ရည်မှန်းထားပေမယ့် အချိန်မှီ ပြီးစီးအောင် တည်ဆောက်နိုင်မှာ မဟုတ်တော့ဘူးလို့ သိရပါတယ်။\n","***** Summary Text (True Value) *****\n","၂၀၂၀ တိုကျို အိုလံပစ် အတွက် ပြိုင်ပွဲကျင်းပမယ့် အားကစားကွင်း တည်ဆောက်မယ့် အစီအစဉ်တွေကို ဂျပန် အစိုးရက ပယ်ဖျက်လိုက်ပါတယ်။\n","***** Summary Text (Generated Text) *****\n","ဂျပန်ဝန်ကြီးချုပ်ရှင်ဇိုအာဘေးက ဆောက်လုပ်စားရိတ် အများဆုံး ဖြစ်တယ်လို့ ပြောလိုက်ပါတယ်။\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","# Predict with test data (first 5 rows)\n","sample_dataloader = DataLoader(\n","    tokenized_ds[\"test\"].with_format(\"torch\"),\n","    collate_fn=data_collator,\n","    batch_size=5)\n","for batch in sample_dataloader:\n","    with torch.no_grad():\n","        preds = model.generate(\n","            batch[\"input_ids\"].to(device),\n","            num_beams=15,\n","            num_return_sequences=1,\n","            no_repeat_ngram_size=1,\n","            remove_invalid_values=True,\n","            max_length=128,\n","        )\n","    labels = batch[\"labels\"]\n","    break\n","\n","# Replace -100 (see above)\n","labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n","\n","# Convert id tokens to text\n","text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n","text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","# Show result\n","print(\"***** Input's Text *****\")\n","print(ds[\"test\"][\"text\"][0])\n","print(\"***** Summary Text (True Value) *****\")\n","print(text_labels[0])\n","print(\"***** Summary Text (Generated Text) *****\")\n","print(text_preds[0])"]},{"cell_type":"code","execution_count":null,"id":"a4da2045","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4da2045","outputId":"bb30fb87-e537-4229-c7e1-1ff5f16893ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["***** Input's Text *****\n","ဒေါ်အောင်ဆန်းစုကြည်နဲ့ NLD အမတ်များတွေ့ဆုံပွဲ ဒီနေ့မနက်မှာပြုလုပ်ခဲ့တဲ့ တွေ့ဆုံပွဲမှာ ကိုယ်စားလှယ်တွေအနေနဲ့ ကိုယ့်ရဲ့ ဆွေမျိုးတွေကို အကူအညီ မပေးဖို့နဲ့ အကူအညီပေးခဲ့ပါက ဥပဒေနဲ့အညီအရေးယူသွားမှာဖြစ်ကြောင်း ပြောကြားခဲ့တယ်လို့ တွေ့ ဆုံပွဲကို တက်ရောက်ခဲ့တဲ့ ကိုယ်စားလှယ်တွေက ဘီဘီစီကိုပြောပါတယ်။ NLD ပါတီက လွှတ်တော်ကိုယ်စားလှယ်တွေကို စောင့်ကြည့်ဖို့ အတွက် စည်းကမ်းထိန်းသိမ်းရေး အဖွဲ့ကို လည်း ဖွဲ့စည်းသွားမှာဖြစ်ကြောင်း တွေ့ဆုံပွဲမှာ ပြောကြားခဲ့ပါတယ်။ အမတ်တွေ ဖွဲ့စည်းပုံဥပဒေ ပါတီစည်းမျဉ်းစည်းကမ်းတွေကို လေ့လာရမယ်။ ပါတီရံပုံငွေအတွက် ပြည် ထောင်စုအဆင့်အမတ်ကို ရတဲ့လစာထဲက (၂)သိန်းခွဲဖြတ်တောက်မယ်။ ထိပ်ပိုင်းကလူတွေကို လစာ တဝက် လောက်အထိ ဖြတ်မယ်၊ပြီးတော့ (၅)နှစ်အတွင်း ပိုင်ဆိုင်မှုတွေ အချိန်မရွေးစစ်မယ်လို့တွေ့ဆုံ ပွဲမှာပြောခဲ့တယ်လို့ အမျိုးသားဒီမိုကရေစီအဖွဲ့ချုပ်ပါတီ အနိုင်ရလွှတ်တော်ကိုယ်စားလှယ် ဒေါ်သက်သက် ခိုင်က မီဒီယာတွေကို ပြန်ပြောပြပါတယ်။\n","***** Summary Text (True Value) *****\n","ဒေါ်အောင်ဆန်းစုကြည် နဲ့ အနိုင်ရ NLDလွှတ်တော်ကိုယ်စားလှယ်များတွေ့ဆုံပွဲကို ရန်ကုန်မြို့ တော်ဝင်နှင်းဆီခန်းမမှာ ပြုလုပ်ခဲ့ပါတယ်။\n","***** Summary Text (Generated Text) *****\n","အမျိုးသားဒီမိုကရေစီအဖွဲ့ချုပ်ပါတီ အနိုင်ရလွှတ်တော်ကိုယ်စားလှယ် ဦးအောင်ဆန်းစုကြည်နဲ့ NLD ပါတီအမတ်များတွေ့ဆုံပွဲကို ဒီနေ့ မနက်ပိုင်းမှာပြုလုပ်ခဲ့ပါတယ်။\n"]}],"source":["print(\"***** Input's Text *****\")\n","print(ds[\"test\"][\"text\"][2])\n","print(\"***** Summary Text (True Value) *****\")\n","print(text_labels[2])\n","print(\"***** Summary Text (Generated Text) *****\")\n","print(text_preds[2])"]},{"cell_type":"code","execution_count":null,"id":"e7b4c854","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["295ae145060f4e93ad8d013a52c5f3d9","c40af0db836840e4bf479d955514f357","7cff15c18f754000ae3ec1f3ec3baa66","3967685c7308434f8591e310fc53a993","396f54746e064d03bda9c18e35297d5b","5d49b79034fd451e83dda0bcea754ea4","1dc59df0d24942bdaf8534743f83cc08","0ff65b46ac8a40d7afbf11d85e187b99","f56c4862abe447768342e0cc99517311","5a8b28fa65374a2c94c2152f185d7689","098bcbc677364abcb68caf3dcf8821df","9941c425d5154a17b007422ade051634","6827c3feb29947a0b65922b1d14e150b","9a08dcd118dd4ed8a427755eadd28bb1","d31e8c08224b4a4eb53855bc14775bab","2a192424dda14643a83c54617f0c89b2","62c5da1b667c468f94d57069570c3aa8","da311d93963049e7833827976dd76846","2859e0f4c3934cb2acc221a3bd164960","da0fe5d3b84246a584a59c6a300c5a41","59cfb1f5d7fe4b359debd95cf21ce0b4","f55a47bc37be4d2ebfa3b64da3ca7543","6d996909d5034d2b8061afa4051261f1","1b3a0bd1db364032948edd4d80522a77","aa2fedf4d1c7431dac93318f221bd92d","11e616e2dacd47768c2c5d888a8e35bd","895aa5733a3e4e2088c3242cd4822924","04cd363b3bb24acf81f62d3e704d1e6f","f7721c4910f64934859083d5dcfc228b","ecbfda0591aa4e22869c615ccca04949","d9ae8c1dc86b40ef93a28596815e131a","d49612ea4fd64cfd979016f0fa80db34"]},"id":"e7b4c854","outputId":"3e779b67-febb-495c-9317-6e3fb8bd0cbf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"295ae145060f4e93ad8d013a52c5f3d9"}},"metadata":{}}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","source":["pip install --upgrade transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":585},"id":"gj-5WaX0zu4J","outputId":"3256f1b2-bba9-4366-a5ac-79024f746f5a"},"id":"gj-5WaX0zu4J","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Collecting transformers\n","  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.2\n","    Uninstalling transformers-4.35.2:\n","      Successfully uninstalled transformers-4.35.2\n","Successfully installed transformers-4.37.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["transformers"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["# Pushing model to HuggingFace"],"metadata":{"id":"FBQ0VRkCXr_s"},"id":"FBQ0VRkCXr_s"},{"cell_type":"code","source":["# from transformers import push_to_hub\n","\n","# # Replace \"path_to_your_model_directory\" with the path to your saved model directory\n","# path_to_your_model_directory = \"./trained_for_summarization_jp\"\n","\n","# # Push the model to the Hugging Face model hub\n","# push_to_hub(model_type=\"seq2seq\", model_folder=path_to_your_model_directory, use_temp_dir=True, model_id=\"finetune-xlsum-my\")\n"],"metadata":{"id":"JT1wrcgIuceu"},"id":"JT1wrcgIuceu","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j_DH5btKwiHb"},"id":"j_DH5btKwiHb","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b98efe7c02c94dd59c489c55c425efb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfc83781cb48416db03d9d6a0ebecc06","IPY_MODEL_5abfdbab30db4406aadc4f42dd0d388d","IPY_MODEL_0eaefc4c984a4b9eb0ce41467f297148"],"layout":"IPY_MODEL_6b48d53872f2490f80e5dc170706fa99"}},"cfc83781cb48416db03d9d6a0ebecc06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40b3a0ae71c347bf94cc33bab668d351","placeholder":"​","style":"IPY_MODEL_c2e37d7d4e8b4d01baca58cfddd26828","value":"Map: 100%"}},"5abfdbab30db4406aadc4f42dd0d388d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ef29c7796f640b4833b653b94a5fa28","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_caa141f9a49c44428675b2c1fd08b4ee","value":570}},"0eaefc4c984a4b9eb0ce41467f297148":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b25d6811c6a4d5b99b808ec074c128d","placeholder":"​","style":"IPY_MODEL_bd37436537bc4e279ffcc2f6d4945298","value":" 570/570 [00:01&lt;00:00, 333.20 examples/s]"}},"6b48d53872f2490f80e5dc170706fa99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40b3a0ae71c347bf94cc33bab668d351":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2e37d7d4e8b4d01baca58cfddd26828":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ef29c7796f640b4833b653b94a5fa28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa141f9a49c44428675b2c1fd08b4ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b25d6811c6a4d5b99b808ec074c128d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd37436537bc4e279ffcc2f6d4945298":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"295ae145060f4e93ad8d013a52c5f3d9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_59cfb1f5d7fe4b359debd95cf21ce0b4","IPY_MODEL_f55a47bc37be4d2ebfa3b64da3ca7543","IPY_MODEL_6d996909d5034d2b8061afa4051261f1","IPY_MODEL_1b3a0bd1db364032948edd4d80522a77"],"layout":"IPY_MODEL_1dc59df0d24942bdaf8534743f83cc08"}},"c40af0db836840e4bf479d955514f357":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ff65b46ac8a40d7afbf11d85e187b99","placeholder":"​","style":"IPY_MODEL_f56c4862abe447768342e0cc99517311","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"7cff15c18f754000ae3ec1f3ec3baa66":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5a8b28fa65374a2c94c2152f185d7689","placeholder":"​","style":"IPY_MODEL_098bcbc677364abcb68caf3dcf8821df","value":""}},"3967685c7308434f8591e310fc53a993":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_9941c425d5154a17b007422ade051634","style":"IPY_MODEL_6827c3feb29947a0b65922b1d14e150b","value":true}},"396f54746e064d03bda9c18e35297d5b":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_9a08dcd118dd4ed8a427755eadd28bb1","style":"IPY_MODEL_d31e8c08224b4a4eb53855bc14775bab","tooltip":""}},"5d49b79034fd451e83dda0bcea754ea4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a192424dda14643a83c54617f0c89b2","placeholder":"​","style":"IPY_MODEL_62c5da1b667c468f94d57069570c3aa8","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"1dc59df0d24942bdaf8534743f83cc08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"0ff65b46ac8a40d7afbf11d85e187b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f56c4862abe447768342e0cc99517311":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a8b28fa65374a2c94c2152f185d7689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"098bcbc677364abcb68caf3dcf8821df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9941c425d5154a17b007422ade051634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6827c3feb29947a0b65922b1d14e150b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a08dcd118dd4ed8a427755eadd28bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d31e8c08224b4a4eb53855bc14775bab":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"2a192424dda14643a83c54617f0c89b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62c5da1b667c468f94d57069570c3aa8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da311d93963049e7833827976dd76846":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2859e0f4c3934cb2acc221a3bd164960","placeholder":"​","style":"IPY_MODEL_da0fe5d3b84246a584a59c6a300c5a41","value":"Connecting..."}},"2859e0f4c3934cb2acc221a3bd164960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da0fe5d3b84246a584a59c6a300c5a41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59cfb1f5d7fe4b359debd95cf21ce0b4":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa2fedf4d1c7431dac93318f221bd92d","placeholder":"​","style":"IPY_MODEL_11e616e2dacd47768c2c5d888a8e35bd","value":"Token is valid (permission: write)."}},"f55a47bc37be4d2ebfa3b64da3ca7543":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_895aa5733a3e4e2088c3242cd4822924","placeholder":"​","style":"IPY_MODEL_04cd363b3bb24acf81f62d3e704d1e6f","value":"Your token has been saved in your configured git credential helpers (store)."}},"6d996909d5034d2b8061afa4051261f1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7721c4910f64934859083d5dcfc228b","placeholder":"​","style":"IPY_MODEL_ecbfda0591aa4e22869c615ccca04949","value":"Your token has been saved to /root/.cache/huggingface/token"}},"1b3a0bd1db364032948edd4d80522a77":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9ae8c1dc86b40ef93a28596815e131a","placeholder":"​","style":"IPY_MODEL_d49612ea4fd64cfd979016f0fa80db34","value":"Login successful"}},"aa2fedf4d1c7431dac93318f221bd92d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11e616e2dacd47768c2c5d888a8e35bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"895aa5733a3e4e2088c3242cd4822924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04cd363b3bb24acf81f62d3e704d1e6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7721c4910f64934859083d5dcfc228b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecbfda0591aa4e22869c615ccca04949":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9ae8c1dc86b40ef93a28596815e131a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d49612ea4fd64cfd979016f0fa80db34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}